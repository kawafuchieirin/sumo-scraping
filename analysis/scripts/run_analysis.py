#!/usr/bin/env python3
"""
SUUMO ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰å®Ÿè¡Œå¯èƒ½ãªåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Jupyter Notebookã‚’ä½¿ã‚ãšã«åˆ†æã‚’å®Ÿè¡Œã—ãŸã„å ´åˆã«ä½¿ç”¨
"""

import sys
import os
import argparse
from datetime import datetime
import logging

# ãƒ‘ã‚¹ã®è¨­å®š
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from analyzer import SuumoAnalyzer
from visualizer import SuumoVisualizer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('analysis.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ"""
    parser = argparse.ArgumentParser(
        description="SUUMO ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # åŸºæœ¬åˆ†æã®ã¿å®Ÿè¡Œ
  python run_analysis.py --data-path ../../data --basic-only
  
  # å®Œå…¨åˆ†æï¼ˆå¯è¦–åŒ–å«ã‚€ï¼‰
  python run_analysis.py --data-path ../../data --full-analysis
  
  # ç‰¹å®šé§…ã®æ¯”è¼ƒåˆ†æ
  python run_analysis.py --data-path ../../data --compare-stations æ¸‹è°· æ–°å®¿ å“å·
  
  # ãŠå¾—ç‰©ä»¶åˆ†æ
  python run_analysis.py --data-path ../../data --find-deals --rent-percentile 30 --area-percentile 70
        """
    )
    
    parser.add_argument('--data-path', default='../../data',
                       help='ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ../../data)')
    parser.add_argument('--output-dir', default='../reports',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ../reports)')
    parser.add_argument('--latest-only', action='store_true',
                       help='æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ä½¿ç”¨')
    
    # åˆ†æãƒ¢ãƒ¼ãƒ‰
    parser.add_argument('--basic-only', action='store_true',
                       help='åŸºæœ¬åˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--full-analysis', action='store_true',
                       help='å®Œå…¨åˆ†æï¼ˆå¯è¦–åŒ–å«ã‚€ï¼‰ã‚’å®Ÿè¡Œ')
    parser.add_argument('--visualize-only', action='store_true',
                       help='å¯è¦–åŒ–ã®ã¿å®Ÿè¡Œ')
    
    # ç‰¹å®šåˆ†æ
    parser.add_argument('--compare-stations', nargs='+',
                       help='æ¯”è¼ƒã™ã‚‹é§…åã®ãƒªã‚¹ãƒˆ')
    parser.add_argument('--find-deals', action='store_true',
                       help='ãŠå¾—ç‰©ä»¶åˆ†æã‚’å®Ÿè¡Œ')
    parser.add_argument('--rent-percentile', type=float, default=25,
                       help='ãŠå¾—ç‰©ä»¶ã®è³ƒæ–™åˆ†ä½ç‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 25)')
    parser.add_argument('--area-percentile', type=float, default=75,
                       help='ãŠå¾—ç‰©ä»¶ã®é¢ç©åˆ†ä½ç‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 75)')
    parser.add_argument('--max-age', type=int, default=20,
                       help='ãŠå¾—ç‰©ä»¶ã®æœ€å¤§ç¯‰å¹´æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20)')
    
    # å‡ºåŠ›è¨­å®š
    parser.add_argument('--save-html', action='store_true',
                       help='HTMLå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›')
    parser.add_argument('--save-json', action='store_true',
                       help='JSONå½¢å¼ã§åˆ†æçµæœå‡ºåŠ›')
    parser.add_argument('--verbose', action='store_true',
                       help='è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º')
    
    return parser.parse_args()

def print_section_header(title):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã®å‡ºåŠ›"""
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")

def run_basic_analysis(analyzer):
    """åŸºæœ¬åˆ†æã®å®Ÿè¡Œ"""
    print_section_header("åŸºæœ¬çµ±è¨ˆåˆ†æ")
    
    # åŸºæœ¬çµ±è¨ˆ
    basic_stats = analyzer.get_basic_stats()
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
    print(f"   ç·ç‰©ä»¶æ•°: {basic_stats['total_properties']:,} ä»¶")
    print(f"   å¯¾è±¡é§…æ•°: {basic_stats['stations']['count']} é§…")
    print(f"   å¯¾è±¡é§…: {', '.join(basic_stats['stations']['list'])}")
    
    if 'rent' in basic_stats:
        rent_stats = basic_stats['rent']
        print(f"\nğŸ’° è³ƒæ–™çµ±è¨ˆ:")
        print(f"   å¹³å‡: {rent_stats['mean']:,.0f} å††")
        print(f"   ä¸­å¤®å€¤: {rent_stats['median']:,.0f} å††")
        print(f"   æœ€å°-æœ€å¤§: {rent_stats['min']:,.0f} - {rent_stats['max']:,.0f} å††")
    
    if 'area' in basic_stats:
        area_stats = basic_stats['area']
        print(f"\nğŸ“ é¢ç©çµ±è¨ˆ:")
        print(f"   å¹³å‡: {area_stats['mean']:.1f} ã¡")
        print(f"   ä¸­å¤®å€¤: {area_stats['median']:.1f} ã¡")
    
    # é§…åˆ¥åˆ†æ
    try:
        print_section_header("é§…åˆ¥åˆ†æ")
        station_analysis = analyzer.analyze_rent_by_station()
        
        print("ğŸ’° è³ƒæ–™TOP5é§…:")
        top_stations = station_analysis.nlargest(5, 'rent_numeric_mean')
        for i, (_, row) in enumerate(top_stations.iterrows(), 1):
            print(f"  {i}. {row['search_station']}: {row['rent_numeric_mean']:,.0f}å††")
        
        print("\nğŸ’¸ è³ƒæ–™å®‰ä¾¡TOP5é§…:")
        bottom_stations = station_analysis.nsmallest(5, 'rent_numeric_mean')
        for i, (_, row) in enumerate(bottom_stations.iterrows(), 1):
            print(f"  {i}. {row['search_station']}: {row['rent_numeric_mean']:,.0f}å††")
            
    except Exception as e:
        logger.warning(f"é§…åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    # é–“å–ã‚Šåˆ†æ
    try:
        print_section_header("é–“å–ã‚Šåˆ†æ")
        layout_analysis = analyzer.analyze_layout_distribution()
        
        print("ğŸ  é–“å–ã‚Šåˆ†å¸ƒ:")
        for _, row in layout_analysis.head(10).iterrows():
            print(f"  {row['layout']}: {row['rent_numeric_count']}ä»¶ ({row['percentage']:.1f}%)")
            
    except Exception as e:
        logger.warning(f"é–“å–ã‚Šåˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    return basic_stats

def run_deal_analysis(analyzer, rent_percentile, area_percentile, max_age):
    """ãŠå¾—ç‰©ä»¶åˆ†æã®å®Ÿè¡Œ"""
    print_section_header("ãŠå¾—ç‰©ä»¶åˆ†æ")
    
    try:
        deals = analyzer.find_deals(
            rent_percentile=rent_percentile,
            area_percentile=area_percentile,
            max_age=max_age
        )
        
        print(f"ğŸ¯ æ¤œç´¢æ¡ä»¶:")
        print(f"   è³ƒæ–™: ä¸‹ä½{rent_percentile}%ä»¥ä¸‹")
        print(f"   é¢ç©: ä¸Šä½{100-area_percentile}%ä»¥ä¸Š")
        print(f"   ç¯‰å¹´æ•°: {max_age}å¹´ä»¥å†…")
        
        if len(deals) > 0:
            print(f"\nâœ¨ ç™ºè¦‹ã•ã‚ŒãŸãŠå¾—ç‰©ä»¶: {len(deals)}ä»¶")
            
            # TOP10è¡¨ç¤º
            print("\nğŸ† ãŠå¾—åº¦TOP10:")
            top_deals = deals.head(10)
            
            for i, (_, deal) in enumerate(top_deals.iterrows(), 1):
                title = deal.get('building_title', 'ä¸æ˜')
                station = deal.get('search_station', 'ä¸æ˜')
                rent = deal.get('rent_numeric', 0)
                area = deal.get('area_numeric', 0)
                score = deal.get('deal_score', 0)
                
                print(f"  {i:2d}. {title[:20]:<20} | {station:<8} | {rent:>8,.0f}å†† | {area:>5.1f}ã¡ | {score:.3f}")
        else:
            print("\nğŸ˜” æ¡ä»¶ã«åˆã†ãŠå¾—ç‰©ä»¶ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
    except Exception as e:
        logger.error(f"ãŠå¾—ç‰©ä»¶åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

def run_station_comparison(analyzer, stations):
    """é§…é–“æ¯”è¼ƒåˆ†æã®å®Ÿè¡Œ"""
    print_section_header(f"é§…é–“æ¯”è¼ƒåˆ†æ: {', '.join(stations)}")
    
    try:
        comparison = analyzer.compare_stations(stations)
        
        if len(comparison) > 0:
            print("ğŸ“Š æ¯”è¼ƒçµæœ:")
            print(f"{'é§…å':<10} {'ä»¶æ•°':<6} {'å¹³å‡è³ƒæ–™':<10} {'å¹³ç±³å˜ä¾¡':<10} {'ã‚³ã‚¹ãƒ‘é †ä½':<8}")
            print("-" * 60)
            
            for _, row in comparison.iterrows():
                station = row['search_station']
                count = row['rent_numeric_count']
                avg_rent = row['rent_numeric_mean']
                rent_per_sqm = row.get('rent_per_sqm_mean', 0)
                cp_rank = row.get('cost_performance_rank', 0)
                
                print(f"{station:<10} {count:<6.0f} {avg_rent:<10,.0f} {rent_per_sqm:<10,.0f} {cp_rank:<8.0f}")
        else:
            print("âš ï¸ æŒ‡å®šã•ã‚ŒãŸé§…ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
    except Exception as e:
        logger.error(f"é§…é–“æ¯”è¼ƒåˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

def run_visualization(analyzer, output_dir):
    """å¯è¦–åŒ–ã®å®Ÿè¡Œ"""
    print_section_header("ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")
    
    try:
        visualizer = SuumoVisualizer(analyzer.df, output_dir=os.path.join(output_dir, "visualizations"))
        generated_files = visualizer.generate_all_visualizations()
        
        print("ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸå¯è¦–åŒ–:")
        for key, description in generated_files.items():
            print(f"   âœ… {description}")
        
        print(f"\nğŸ“‚ ä¿å­˜å…ˆ: {visualizer.output_dir}")
        return True
        
    except Exception as e:
        logger.error(f"å¯è¦–åŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def save_results(analyzer, output_dir, save_json, save_html):
    """çµæœã®ä¿å­˜"""
    print_section_header("çµæœä¿å­˜")
    
    os.makedirs(output_dir, exist_ok=True)
    
    if save_json:
        try:
            json_path = analyzer.export_analysis_results(
                os.path.join(output_dir, "analysis_results.json")
            )
            print(f"ğŸ’¾ JSONçµæœä¿å­˜: {json_path}")
        except Exception as e:
            logger.error(f"JSONä¿å­˜ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    if save_html:
        try:
            from utils import export_report
            html_path = export_report(
                analyzer.df,
                os.path.join(output_dir, "analysis_report.html"),
                "SUUMO ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ"
            )
            print(f"ğŸ’¾ HTMLãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {html_path}")
        except Exception as e:
            logger.error(f"HTMLãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã§ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    args = parse_arguments()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    print("ğŸ”„ SUUMO ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹")
    print(f"ğŸ“… å®Ÿè¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {args.data_path}")
    print(f"ğŸ“¤ å‡ºåŠ›ãƒ‘ã‚¹: {args.output_dir}")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åˆ†æå™¨åˆæœŸåŒ–
        print_section_header("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
        analyzer = SuumoAnalyzer(
            data_path=args.data_path,
            auto_load=True
        )
        
        if analyzer.df is None:
            logger.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return 1
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(analyzer.df)} ä»¶")
        
        # åˆ†æå®Ÿè¡Œ
        if args.basic_only or args.full_analysis or (not any([args.visualize_only, args.compare_stations, args.find_deals])):
            run_basic_analysis(analyzer)
        
        if args.compare_stations:
            run_station_comparison(analyzer, args.compare_stations)
        
        if args.find_deals:
            run_deal_analysis(analyzer, args.rent_percentile, args.area_percentile, args.max_age)
        
        if args.visualize_only or args.full_analysis:
            run_visualization(analyzer, args.output_dir)
        
        # çµæœä¿å­˜
        if args.save_json or args.save_html:
            save_results(analyzer, args.output_dir, args.save_json, args.save_html)
        
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if args.full_analysis:
            print_section_header("ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")
            summary = analyzer.generate_summary_report()
            
            print("ğŸ” ä¸»è¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆ:")
            for i, insight in enumerate(summary.get('insights', []), 1):
                print(f"  {i}. {insight}")
        
        print_section_header("åˆ†æå®Œäº†")
        print("âœ… ã™ã¹ã¦ã®åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        return 0
        
    except KeyboardInterrupt:
        logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 1
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1

if __name__ == "__main__":
    exit(main())